{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Joao_Vitor_LSTM_Bankxlsx.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AtcXAvvgH3Rf",
        "colab_type": "text"
      },
      "source": [
        "# Treinamento de IA Stefanini\n",
        "##Nome: João Vitor Rodrigues Baptista\n",
        "## [Github](https://github.com/helpthx) \n",
        "##[LinkedIn](https://www.linkedin.com/in/jo%C3%A3o-vitor-rodrigues-baptista-4a3546149/) \n",
        "\n",
        "### Para as datas devem predizer qual são os montantes para os próximos pontos de entrada na validação e teste. E verificar em uma outra predição os pontos de melhores clientes. Lembrando que não quero a melhor predição e sim como irá ficar a arquitetura e as explicações.\n",
        "\n",
        "#### Atributos:\n",
        "Account No. - representa o número da conta envolvida na transação.\\\n",
        "Date - data da transação.\\\n",
        "Transaction Details - narrações de transação em extratos bancários.\\\n",
        "Cheque No. - indica o número do cheque.\\\n",
        "Value Date - Data de conclusão da transação.\\\n",
        "Withdrawal Amount - Indica o montante retirado.\\\n",
        "Deposit Amount - Indica o valor depositado.\\\n",
        "Balance Amount - saldo atual da conta.\n",
        "\n",
        "### Jupyter do google Google Colab treinado usando GPU.\n",
        "[Google Colab](https://colab.research.google.com/drive/1q8y010qy7E0bOYZ2Y7u9OL7YyEDTd8Im#scrollTo=AtcXAvvgH3Rf)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BDUMRvaiWZbh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import sys\n",
        "import time\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import pickle\n",
        "import logging\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras.layers import LSTM\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau,\\\n",
        "CSVLogger\n",
        "from keras import optimizers\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from tqdm._tqdm_notebook import tqdm_notebook\n",
        "from tensorflow.python.client import device_lib\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from matplotlib import pyplot as plt\n",
        "device_lib.list_local_devices()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qNiTYXzhVTEL",
        "colab_type": "text"
      },
      "source": [
        "### 1 - Fiz uma pequena pesquisa para verificar de onde poderia ter vindo os dados.\n",
        "\n",
        "Encontrei que é um padrão de dados vindo de um tipo de servico bancario da India. Chamado HDFC Bank.\n",
        "\n",
        "Referências: \\\n",
        "[1](https://towardsdatascience.com/predicting-stock-price-with-lstm-13af86a74944)\\\n",
        "[2](https://towardsdatascience.com/find-your-best-customers-with-customer-segmentation-in-python-61d602f9eee6)\\\n",
        "[3](https://medium.com/@_samkitjain/developing-a-bank-statement-analyser-7470bffbe5e2)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JMa3Max_Xd2U",
        "colab_type": "text"
      },
      "source": [
        "#### 2 - Lendo e Analizando os dados "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mAl3Qv3ZvUWx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Foi feita uma conversão de xlsx -> csv, apenas salvando o excel em csv\n",
        "df_ge = pd.read_excel('bank.xlsx')\n",
        "df_ge.tail()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bk35oPI13bmW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_ge.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QxVu5RiOX60E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(len(df_ge))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v4tE5LdnidkS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"Verificando a quantidade de valores NaN\\n\", df_ge.isna().sum())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VhIScRRugjYz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_ge.iloc[[21996]]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8GU6EOERkls5",
        "colab_type": "text"
      },
      "source": [
        "#### 3 - Tratando os NaN, tipos de dados e valores negaticos do dataframe "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cIULMnxfkhS0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Verificando os tipos de dados\n",
        "df_ge['BALANCE AMT'].dtypes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p5F_OonvpFgY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_ge.describe()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YsVq8ppYqdmN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Ploando os valores para avaliar o comportamento das colunas\n",
        "plt.figure(figsize=(10,10))\n",
        "plt.plot(df_ge['CHQ.NO.'])\n",
        "plt.plot(df_ge['WITHDRAWAL AMT'])\n",
        "plt.plot(df_ge['DEPOSIT AMT'])\n",
        "plt.plot(df_ge['BALANCE AMT'])\n",
        "plt.title('Valores continuos do dataset do HDFC Bank')\n",
        "plt.ylabel('Amount (Money)')\n",
        "plt.xlabel('Days')\n",
        "plt.legend(['CHQ.NO.','WITHDRAWAL AMT','DEPOSIT AMT','BALANCE AMT'], \n",
        "           loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bDgNYE_i8ceh",
        "colab_type": "text"
      },
      "source": [
        "Parece que o WITHDRAWAL AMT e o DEPOSIT AMT não variam tanto ao longo dos dias, comparando os outras features."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iz7GFtyf6aAT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Ploando os valores para avaliar o comportamento das colunas\n",
        "plt.figure(figsize=(10,10))\n",
        "plt.plot(df_ge['WITHDRAWAL AMT'])\n",
        "plt.plot(df_ge['DEPOSIT AMT'])\n",
        "plt.title('Valores continuos do dataset do HDFC Bank')\n",
        "plt.ylabel('Amount (Money)')\n",
        "plt.xlabel('Days')\n",
        "plt.legend(['WITHDRAWAL AMT','DEPOSIT AMT'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jRK8PSrd_kj7",
        "colab_type": "text"
      },
      "source": [
        "### 4 - Normalizando os dados/ Partindo os dados em treino/teste\n",
        "Como os dados não estão numa mesma escala é necessario fazer a normalização. Com a normalização é possivel convergir os dados para um local/global minino eficientemente."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "esm2Ql0h3Jtm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_ge=df_ge.fillna({'WITHDRAWAL AMT':0.0})\n",
        "df_ge.head()\n",
        "\n",
        "dataset = df_ge.filter(items =['WITHDRAWAL AMT'])\n",
        "dataset.tail(5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BWFnnk4nDJv-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset.head(5)\n",
        "len(dataset)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t8K6H3fv6Xux",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset.describe()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UjqxZoLx6eQT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset.plot()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7PJMjDQw-ipA",
        "colab_type": "text"
      },
      "source": [
        "Para obter o valor do próximo dado, 60 registros anteriores são usados (2 meses). É necessário separar o dataset em treinamento e teste e, em seguida, separar cada pedaço (batch) dessas bases que serão usados nesses processos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "chUJNaLD6mPW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "timesteps = 20"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OqjigzKr-w4Q",
        "colab_type": "text"
      },
      "source": [
        "A normalização da base acelera o processo de treinamento, além de amenizar resultados insatisfatórios que podem ocorrer devido à grande variação nos valores durante o treinamento. Fazendo a normalização de 0 até 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9I6hDsCa6nGg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "base = dataset.iloc[:][:].values # Conversão para float\n",
        "normalizador = MinMaxScaler(feature_range=(0,1))\n",
        "base_normalizada = normalizador.fit_transform(base)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wnmdjhmk-TNR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(base_normalizada)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LKRVScYlDtpV",
        "colab_type": "text"
      },
      "source": [
        "Seperando o dataset em batchs de treinamento e testes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VVqxGUKm6srH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = base_normalizada[0:(len(base) - (len(base) % timesteps))] # Previsores\n",
        "\n",
        "# Batches com tamanho = timesteps. Quantidade = (total de registros / timesteps)\n",
        "X_batches = X.reshape(-1, timesteps, 1) \n",
        "Y = base_normalizada[1:(len(base) - (len(base) % timesteps)) + 1] # Valores reais\n",
        "y_batches = Y.reshape(-1, timesteps, 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Svrw7d0FD18g",
        "colab_type": "text"
      },
      "source": [
        "Criação e normalização das bases de testes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mpleYYeQ3HM2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " # Últimos registros do banco. (len(banco) - timesteps) até o final dele\n",
        "X_teste = base[-(timesteps + 1):]\n",
        "X_teste = X_teste[:timesteps]\n",
        "X_teste = normalizador.transform(X_teste)\n",
        "X_teste = X_teste.reshape(-1, timesteps, 1) # Reshape para input do tensorflow\n",
        "\n",
        "# Reparar que o y_teste não utiliza a base normalizada\n",
        "y_teste = base[-(timesteps):] \n",
        "y_teste = y_teste.reshape(-1, timesteps, 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jnuvtQ7rE6pK",
        "colab_type": "text"
      },
      "source": [
        "### Criando o modelo usando RNN do tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gXPX8jN96xwX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Número de nós em cada camada\n",
        "n_input = 1\n",
        "n_hidden = 120\n",
        "n_output = 1\n",
        "\n",
        "# Variaveis de treinamento\n",
        "epocas = 1000\n",
        "n_display = epocas/10\n",
        "\n",
        "tf.reset_default_graph() # Reseta o grafo atual\n",
        "\n",
        "# Criação dos placeholders\n",
        "x = tf.placeholder(tf.float32, [None, timesteps, n_input])\n",
        "y = tf.placeholder(tf.float32, [None, timesteps, n_output])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PrcbS5Oc7Fzv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Função para criar uma célula LSTM\n",
        "def inicializarUmaCelula():\n",
        "    return tf.contrib.rnn.LSTMCell(num_units = n_hidden, \n",
        "                                   activation = tf.nn.relu)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cYe-SeKd7IdI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Função para criar n células LSTM\n",
        "def inicializarVariasCelulas(n_celulas):\n",
        "    celulas =  tf.nn.rnn_cell.MultiRNNCell(\n",
        "        [inicializarUmaCelula() for i in range(n_celulas)])\n",
        "    \n",
        "    return tf.contrib.rnn.DropoutWrapper(celulas, input_keep_prob = 0.9) # Dropout"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N7f1v6Ge7KL7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Criação das células\n",
        "celula = inicializarVariasCelulas(4) # 3 células\n",
        "celula = tf.contrib.rnn.OutputProjectionWrapper(celula, output_size = 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pL9zhYF9FTiz",
        "colab_type": "text"
      },
      "source": [
        "Erros e métricas:\n",
        "O otimizador mais adequado, depois de vários testes, foi o Adam A função de erro escolhida foi a MSE."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jh6Rz-7z7amH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "saida_rnn, _ = tf.nn.dynamic_rnn(celula, x, dtype = tf.float32)\n",
        "erro = tf.losses.mean_squared_error(labels = y, predictions = saida_rnn)\n",
        "otimizador = tf.train.AdamOptimizer(learning_rate = 0.001)\n",
        "treinamento = otimizador.minimize(erro)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1P-Bz82I7c8Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Inicializando variáveis globais\n",
        "init = tf.global_variables_initializer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hphC8D0lFqVw",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "Sessão de treinamento:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JVHDJUYU7kxR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with tf.Session() as sess:\n",
        "    sess.run(init)\n",
        "    \n",
        "    for epoca in range(epocas+1):\n",
        "        _, custo = sess.run([treinamento, erro], \n",
        "                            feed_dict = {x: X_batches, y: y_batches})\n",
        "        if epoca % n_display == 0:\n",
        "            print('Epoca:', epoca, '\\terro (MSE):', custo)\n",
        "    \n",
        "    previsoes = sess.run(saida_rnn, feed_dict = {x: X_teste})\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8e6qk-pgFt2i",
        "colab_type": "text"
      },
      "source": [
        "Repare que o erro é bem pequeno devido à normalização"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sMeNVuXxNmg6",
        "colab_type": "text"
      },
      "source": [
        "### Resultados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d425Tw2SNqrL",
        "colab_type": "text"
      },
      "source": [
        "Como essas variáveis estão no shape do tensorflow (3 dimensões), é necessário usar o método ravel para mudar suas dimensões."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N2LhWb5k8t15",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_teste_normal = np.ravel(y_teste)\n",
        "print(y_teste.shape)\n",
        "print(y_teste_normal.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NVmDQx408zzo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "previsoes_normal = np.ravel(previsoes)\n",
        "print(previsoes.shape)\n",
        "print(previsoes_normal.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Brqf8vgcNvE-",
        "colab_type": "text"
      },
      "source": [
        "As previsões devem ser desnormalizadas para comparar com y_teste"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hMmMHrJhEqEu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "previsoes_normal = previsoes_normal.reshape(-1,1) \n",
        "previsoes_normal = normalizador.inverse_transform(previsoes_normal)\n",
        "previsoes_normal = np.squeeze(previsoes_normal) \n",
        "# Para melhor visualização no print"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VHKjzJUaNyua",
        "colab_type": "text"
      },
      "source": [
        "A métrica Mean Absolute Error informa a diferença do valor real com o valor previsto, que é bom para verificar a acurácia do modelo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o6r0bqX484mQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mae = mean_absolute_error(y_teste_normal, previsoes_normal)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zp_g4yr587rT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def exibirResultados():\n",
        "    for i in range(len(previsoes_normal)):\n",
        "        print('Previsão:', previsoes_normal[i], '\\tValor real:', \n",
        "              y_teste_normal[i])\n",
        "    \n",
        "    print()\n",
        "    print('Media do erro absoluto:', round(mae,4))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Mtp3_rNN02i",
        "colab_type": "text"
      },
      "source": [
        "A função exibe um resumo dos resultados obtidos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wHCkgvHX8-73",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "exibirResultados()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N4D1WZbRN4TZ",
        "colab_type": "text"
      },
      "source": [
        "### Visualização do gráfico"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R2qBFGuo9I9o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(y_teste_normal, label = 'Valor real')\n",
        "plt.plot(previsoes_normal, label = 'Previsões')\n",
        "plt.legend()\n",
        "plt.savefig(os.path.join('train_vis_BS__'+time.ctime()+'.png'))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HJ1LC52tN8F1",
        "colab_type": "text"
      },
      "source": [
        "A previsão tem um comportamento parecido com ao valor real, porem existem um descompaso muito grande entre os modulos em cada ponto, o que leva a um erro muito alto"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M1MKPNKhpiSP",
        "colab_type": "text"
      },
      "source": [
        "## Para categorizar os clientes é necessario categorizar o tipo de transação que foi feita em Debit, Credit ou Default"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D1dJtcQEEULb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_ge.tail()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0UprypyApwxT",
        "colab_type": "text"
      },
      "source": [
        "Transformando os valores em lista para fazer uma varredurar usando fors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vS0YSBhnhxyN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rows = df_ge.values.tolist()\n",
        "rows[116199][2]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W-6EbHtIZa5r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Vericando se n existem um balanco vazio na lista\n",
        "# PS: Já verificado no dataframe do pandas\n",
        "\n",
        "headers = []\n",
        "\n",
        "for row in rows:\n",
        "    if row[7] == 'nan':\n",
        "        headers.append(rows)\n",
        "    else:\n",
        "        break\n",
        "\n",
        "valid_transactions = []  \n",
        "\n",
        "for row in rows:\n",
        "    if row not in headers:\n",
        "        valid_transactions.append(row)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-AsKlQi4eMOE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "len(valid_transactions)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2-Yxv2FYkI-3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Iniciando os valores \n",
        "transactions = []                 # lista para guarda os valores da transação\n",
        "d_i = 1        # da data\n",
        "p_i = 2  # posição dos detalhes de transição\n",
        "\n",
        "# iterate over all transactions\n",
        "for v_t in valid_transactions:\n",
        "    if v_t[d_i] is not None:\n",
        "        transactions.append(v_t)\n",
        "    \n",
        "    else:\n",
        "        transactions[-1][p_i] += v_t[p_i]\n",
        "        \n",
        "transactions[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7XdS6z5YmjrX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Posições na lista\n",
        "w_i = 5  # posiçao do withdrawal\n",
        "d_i = 6  # posição do deposito    \n",
        "b_i = 7  # posição do balanco   \n",
        "is_negative = False              \n",
        "final_result = []                \n",
        "# final_result = [][1]'withdrawal'\n",
        "# final_result = [][0]'Type'\n",
        "# 1.00 - debito\n",
        "# -1.00 - credito\n",
        "# 0 - default\n",
        "\n",
        "# Faz interação sob todaas as transações para fazer a classificação dos valores \n",
        "for transaction in transactions:\n",
        "    if transaction[w_i] > 00.00 and transaction[b_i] < 00.00:\n",
        "        if is_negative:\n",
        "            final_result[-1][8] = 1.00\n",
        "        \n",
        "        is_negative = True\n",
        "        transaction[0] = 0\n",
        "        final_result.append(transaction)\n",
        "\n",
        "        continue\n",
        "    \n",
        "    elif is_negative:\n",
        "        if transaction[d_i] == final_result[-1][5]:\n",
        "            transaction[8] = 0\n",
        "    \n",
        "        else:\n",
        "            final_result[-1][8] = 1.00\n",
        "        \n",
        "            if transaction[w_i] > 00.00 and transaction[b_i] < 00.00:\n",
        "                is_negative = True\n",
        "                transaction[8] = 0\n",
        "                final_result.append(tran)\n",
        "            \n",
        "                continue\n",
        "            \n",
        "            # debito\n",
        "            elif transaction[w_i] > 00.00:\n",
        "                transaction[8] = 1.00\n",
        "            \n",
        "            # credito\n",
        "            elif transaction[d_i] > 00.00:\n",
        "                transaction[8] = -1.00\n",
        "    \n",
        "    # debito\n",
        "    elif transaction[w_i] > 00.00:\n",
        "        transaction[8] = 1.00\n",
        "    \n",
        "    # credito\n",
        "    elif transaction[d_i] > 00.00:\n",
        "        transaction[8] = -1.00\n",
        "    \n",
        "    is_negative = False\n",
        "    final_result.append(transaction)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ugOjLjh2myAK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "len(final_result)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yy_Rs7Cuy2yB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.DataFrame(np.array(final_result), \\\n",
        "                  columns = list(\n",
        "    ['AccountNo', 'DATE', 'TRANSACTION DETAILS',\n",
        "     'CHQ.NO', 'VALUE DATE', 'WITHDRAWAL AMT', \n",
        "     'DEPOSIT AMT', 'BALANCE AMT', 'Type']))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CLPtLrYC2z3W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5vhRQUoT_Zqi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.set_index([\"AccountNo\", \"Type\"]).count(level=\"Type\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BLUdyV2zCxdW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.groupby('AccountNo')['Type'].describe()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n-44FFM0EaOL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.groupby('Type')['AccountNo'].describe()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p-zPmkJUGb65",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.pivot_table(index='Type',columns='AccountNo',aggfunc=sum)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EBfwTtDbIYGe",
        "colab_type": "text"
      },
      "source": [
        "A ideia que tive foi que classficando as transações eu poderia pegar o account id de cada cliente e mapeada pela quantidade de vezes que ele fez uma transação de creditos e de depositos para saber se o saldo dele é neutro ou se ele sempre faz mais depositos do que saques. Porem não conseguir pensar uma logica de agregação efetiva desses valores."
      ]
    }
  ]
}